{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-a3d928ce7b64>, line 179)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-a3d928ce7b64>\"\u001b[0;36m, line \u001b[0;32m179\u001b[0m\n\u001b[0;31m    elif percent1 != 0.0 and percent1 == 0.0:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Aaron Feldman\n",
    "#Assignment Two\n",
    "#Professor Manley\n",
    "#Machine Learning\n",
    "#10/13/2016\n",
    "\n",
    "import pandas\n",
    "import random\n",
    "import math\n",
    "from sklearn import cross_validation\n",
    "\n",
    "\n",
    "\n",
    "#the class with functions to be used as entry points when\n",
    "#either training (fit) or predicting (predict) with the\n",
    "#decision tree algorithm\n",
    "class DTree:\n",
    "    def fit(self,predictor_columns_data,target_column_data):\n",
    "        self.__root_node = DNode(predictor_columns_data,target_column_data)\n",
    "        self.__root_node.train()\n",
    "        \n",
    "    def predict(self,df_of_new_examples):\n",
    "        #apply the predict function to the whole series, one at a time, this returns the series with the return vals\n",
    "        predictions = df_of_new_examples.apply(self.__root_node.predict,axis=1)\n",
    "        return predictions\n",
    "        \n",
    "    def print_tree(self):\n",
    "        self.__root_node.print_node()\n",
    "        \n",
    "\n",
    "#A class for representing non-leaf nodes in the decision tree\n",
    "class DNode:\n",
    "    \n",
    "    #when we create this node, we pass it training examples to be used at this point\n",
    "    #the predictor columns of these training examples is in predictor_columns_data\n",
    "    #the corresponding target values to those predictor columns are in target_column_data\n",
    "    def __init__(self,predictor_columns_data,target_column_data):\n",
    "\n",
    "        self.__attribute = ''  #the attribute used to sort examples at this node\n",
    "        self.__predictor_columns = predictor_columns_data #the training examples that have been sorted to this node\n",
    "        self.__target_column = target_column_data #the corresponding target values for the training examples\n",
    "        self.__child_nodes = {} #dictionary of the child nodes of this node, indexed by the value they have for self.__attribute\n",
    "        self.__most_common_value_here = '' #for keeping track of which target value is most common among the examples at this \n",
    "        #node. This is used to make a decision when there's no appropriate child node to follow\n",
    "        \n",
    "    #this should use the training data to determine the best attribute to use\n",
    "    #as is, it just chooses one at random, but you will fix it to use information gain\n",
    "    \n",
    "    def choose_attribute(self):\n",
    "        self.__attribute = random.choice(self.__predictor_columns.columns.values) #what a terrible way to choose the attribute! \n",
    "    '''    \n",
    "        maximum_value = 0\n",
    "        i = 0\n",
    "        best_entropy_value = ''\n",
    "        for i in range(len(self.__predictor_columns.columns.values)):\n",
    "            new_entropy = entropy(credit_data,self.__predictor_columns.columns.values[i])\n",
    "            if new_entropy <= min_entropy:\n",
    "                min_entropy = new_entropy\n",
    "                Best_Entropy = self.__predictor_columns.columns.values[i]\n",
    "       ''' \n",
    "        \n",
    "    #calling this will continue building the tree from this node given its training examples\n",
    "    def train(self):\n",
    "        self.choose_attribute() #'best' attribute at this node\n",
    "        \n",
    "        #in case we need to make a decision here because we don't have any children with a particular attribute value    \n",
    "        self.__most_common_value_here = self.__target_column.value_counts().idxmax()\n",
    "        \n",
    "        #gets all the values that these examples have in our chosen column\n",
    "        attribute_values_here = self.__predictor_columns[self.__attribute].unique()\n",
    "\n",
    "        #going through all possible values this attribute can have\n",
    "        #and creating the appropriate child node\n",
    "        for value in attribute_values_here: \n",
    "             \n",
    "            #the subset of examples with the given value\n",
    "            examples_for_child_predictor_cols = self.__predictor_columns[self.__predictor_columns[self.__attribute] == value] \n",
    "            examples_for_child_target_col = self.__target_column[self.__predictor_columns[self.__attribute] == value] #target values corresponding to the subset of examples with the given value\n",
    "            \n",
    "            #we grabbed the values from the examples themselves, so there should\n",
    "            #be at least one example that has each value, but just in case there isn't\n",
    "            #I don't want to crash the program\n",
    "            if examples_for_child_target_col.empty:\n",
    "                print(\"error: we shouldn't get here\")\n",
    "                \n",
    "            #there are no columns left to use for decisions at the child\n",
    "            #so lets make a leage node based on the most common target value in those examples\n",
    "            elif len(examples_for_child_predictor_cols.columns.values) == 1:  \n",
    "                #create a child with the most common target value here\n",
    "                leaf_child = DLeaf( self.__most_common_value_here )\n",
    "                self.__child_nodes[value] = leaf_child\n",
    "                \n",
    "            #if all child examples have the same target value, we make a leaf node\n",
    "            elif len(examples_for_child_target_col.unique()) == 1: #all child examples have same class\n",
    "                leaf_child = DLeaf( examples_for_child_target_col.unique()[0] ) #make leaf with that class\n",
    "                self.__child_nodes[value] = leaf_child #put the leaf in the dictionary of children nodes\n",
    "                \n",
    "            else: #we have a regular decision node for this attribute value\n",
    "                #get rid of the column for this attribute so it can't be selected again\n",
    "                examples_for_child_predictor_cols = examples_for_child_predictor_cols.drop(self.__attribute,1) \n",
    "                \n",
    "                new_child = DNode(examples_for_child_predictor_cols,examples_for_child_target_col)\n",
    "                new_child.train() #generate the rest of the subtree for this child\n",
    "                self.__child_nodes[value] = new_child #put the new child node in the dictionary of children nodes\n",
    "            \n",
    "\n",
    "    #print out the tree - not the prettiest, but you can see it.\n",
    "    def print_node(self,num_indents = 0):\n",
    "        for i in range(num_indents): \n",
    "            print(\" \",end=''), #print with no newline\n",
    "        print(self.__attribute)\n",
    "        for attr in self.__child_nodes.keys():\n",
    "            for i in range(num_indents): \n",
    "                print(\"|\", end='')\n",
    "            print(\":\"+attr)\n",
    "            self.__child_nodes[attr].print_node(num_indents+1)\n",
    "            \n",
    "    #make a prediction for a single new example\n",
    "    #this only makes sense to call after the tree has been build (with train())\n",
    "    def predict(self,new_example):\n",
    "        #look up the right branch in our dictionary of children\n",
    "        if new_example[self.__attribute] in self.__child_nodes:\n",
    "            node_on_corresponding_branch = self.__child_nodes[new_example[self.__attribute]]\n",
    "            return node_on_corresponding_branch.predict(new_example) #recursively call predict on the child node\n",
    "        else:\n",
    "            return self.__most_common_value_here #there was no child, so we predict the most common class of the examples at this node\n",
    "        \n",
    "#class for representing a leaf node in the tree\n",
    "class DLeaf:\n",
    "    \n",
    "    #when we create the node, all we need to know is what we're going to predict if we get here\n",
    "    def __init__(self,val_in_target_col):\n",
    "        self.__target_value = val_in_target_col\n",
    "    \n",
    "    #just returns the prediction for a new example, \n",
    "    #this was probably called from predict() of a regular node one level up in the tree\n",
    "    def predict(self,new_example):\n",
    "        return self.__target_value\n",
    "    \n",
    "    #for displaying the tree\n",
    "    def print_node(self,num_indents = 0):\n",
    "        for i in range(num_indents): \n",
    "            print(\" \",end='')\n",
    "        print(\"LEAF:\",self.__target_value)\n",
    "        \n",
    "    \n",
    "#simply compares two Pandas series and returns the proportion that match\n",
    "#this can be used to compute the accuracy of the prediction list against\n",
    "#the actual target column\n",
    "def accuracy(series1, series2):\n",
    "    correct = 0.0\n",
    "    for index, value in series1.iteritems():\n",
    "        if value == series2.loc[index]:\n",
    "            correct += 1\n",
    "    return (correct/len(series1))\n",
    "\n",
    "\n",
    "def entropy(credit_data,attr): #defining entropy w/ our credit data from our csv file by using our attributes\n",
    "    target_attribute = credit_data[attr].unique() #creating a target attribute from attributes in our data/making that attr unique\n",
    "    track_entropy = [] #creating an empty array to count entropy\n",
    "    \n",
    "    for i in range(len(target_attribute)):   #creating a for lop to find our good and bad creditability \n",
    "        data = credit_data[credit_data[attribute]==target_attribute[i]]\n",
    "        Credit_Score_1 = data[data['Creditability']==1]\n",
    "        Credit_Score_2 = data[data['Creditability']==2]\n",
    "    \n",
    "        percent1 = len(percent1)/len(data)\n",
    "        percent2 = len(percent2)/len(data)\n",
    "    \n",
    "    \n",
    "       #information gain with log function \n",
    "        \n",
    "        if percent1 == 0.0 and percent2 == 0.0:\n",
    "            entropy = 0.0\n",
    "            count_entropy.append([entropy##########?\n",
    "        elif percent1 == 0.0 and percent2 != 0.0:\n",
    "            entropy = percent1*math.log(percent1,2)-percent2*math.log(percent2,2)\n",
    "            #track_entropy.append([entropy#???????????\n",
    "        elif percent1 != 0.0 and percent1 == 0.0:\n",
    "            entropy = percent1*math.log(percent1,2)-percent2*math.log(percent2,2)\n",
    "            #track_entropy.append([entropy#???????????????\n",
    "        elif percent1 or percent2 != 0.0:\n",
    "            entropy = percent1*math.log(percent1,2)-percent2*math.log(percent2,2)\n",
    "            #track_entropy.append([entropy#??????????????\n",
    "    \n",
    "    \n",
    "    for x in range(len(track_entropy)):\n",
    "        total_entropy = (track_entropy[x][1]/len(credit_data))*track_entropy[x][0]\n",
    "    return total_entropy \n",
    "    \n",
    "    #create a running total of entropy. Of which, the highest entropy will be chosen in choose attribute function. \n",
    "\n",
    "#binning\n",
    "credit_data['Duration in month'] = pandas.cut(credit_data['Duration in month'],[0,18,36,54,72],labels=[\"Very short\",\"Short\", \"Long\", \"Very Long\"])\n",
    "credit_data['Credit amount'] = pandas.cut(credit_data['Credit amount'],3, labels = ['low', 'medium', 'high'])\n",
    "credit_data['Installment rate in percentage of disposable income'] = pandas.cut(credit_data['Installment rate in percentage of disposable income'],[0, 2, 4],labels=[\"low\", \"high\"])\n",
    "credit_data['Present residence since'] = pandas.cut(credit_data['Present residence since'],[0,2,4],labels=[\"Recent\", \"Long-time\"])\n",
    "credit_data['Age in years'] = pandas.cut(credit_data['Age in years'],[0, 55, 115],labels=[\"Young\", \"Old\"])\n",
    "credit_data['Number of existing credits at this bank'] = pandas.cut(credit_data['Number of existing credits at this bank'],4)\n",
    "credit_data['Number of people being liable to provide maintenance for'] = pandas.cut(credit_data['Number of people being liable to provide maintenance for'],2)\n",
    "\n",
    "\n",
    "credit_data = pandas.read_csv('german_credit.csv') #dtype='str')\n",
    "train_data, test_data = \\\n",
    "cross_validation.train_test_split(credit_data,test_size = 0.1)\n",
    "#str('Duration in month')\n",
    "attributes_to_use = ['Status of existing checking account','Credit history','Purpose', \\\n",
    "                     'Savings account/bonds', 'Present employment since', \\\n",
    "                     'Personal status and sex', 'Other debtors / guarantors', \\\n",
    "                     'Property', 'Other installment plans', 'Housing', 'Job', 'Duration in month', 'Credit amount', \\\n",
    "                    'Installment rate in percentage of disposable income', 'Present residence since', 'Age in years', \\\n",
    "                    'Number of existing credits at this bank', 'Number of people being liable to provide maintenance for']\n",
    "\n",
    "#Numeric Data type Columns\n",
    "\n",
    "#'Duration in month'\n",
    "#'Credit amount'\n",
    "#'Installment rate in percentage of disposable income'\n",
    "# 'Present residence since'\n",
    "#'Age in years'\n",
    "#'Number of existing credits at this bank',\n",
    "#'Number of people being liable to provide maintenance for'\n",
    "\n",
    "\n",
    "\n",
    "my_tree = DTree()\n",
    "my_tree.fit(train_data[attributes_to_use],train_data['Creditability'])\n",
    "#my_tree.print_tree()\n",
    "predictions = my_tree.predict(test_data[attributes_to_use])\n",
    "print(accuracy(test_data['Creditability'],predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
